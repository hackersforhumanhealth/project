{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/apache-spark/libexec\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()\n",
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check child execution processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.3.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "rdd = sc.parallelize(xrange(10),10)\n",
    "rdd.map(lambda x: sys.version).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.types import *\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colnames=['bounding_box','city','country','text','tid','timestamp','uid']\n",
    "#pandas_df = pd.read_csv('./tweets.csv', delimiter=',', skiprows=1, names=colnames, usecols=[1,2,3,4,5,6,7])\n",
    "#pandas_df = pd.read_csv('./tweets.csv', usecols=[3])\n",
    "#pandas_df.head(5)\n",
    "#alltweets_df = sqlsc.createDataFrame(pandas_df)\n",
    "#alltweets_df.printSchema()\n",
    "#alltweets_df.show(5)\n",
    "#ustweets_df = alltweets_df[alltweets_df['country'] == \"United States\"]\n",
    "#ustweets_df = alltweets_df.filter(alltweets_df['country'] == \"United States\")\n",
    "#print \"Count of All tweets =\", alltweets_df.count()\n",
    "#print \"Count of US tweets:\", ustweets_df.count()\n",
    "#ustweets_df.show(5)\n",
    "#pandas_df.country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets:  37519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[u'0',\n",
       "  u'\"{u\\'type\\': u\\'Polygon\\'',\n",
       "  u\" u'coordinates': [[[-118.082615\",\n",
       "  u' 33.628991]',\n",
       "  u' [-118.082615',\n",
       "  u' 33.756093]',\n",
       "  u' [-117.91485',\n",
       "  u' 33.756093]',\n",
       "  u' [-117.91485',\n",
       "  u' 33.628991]]]}\"',\n",
       "  u'Huntington Beach',\n",
       "  u'United States',\n",
       "  u'In need of back rub',\n",
       "  u'669375138903666692',\n",
       "  u'1448426444160',\n",
       "  u'1611125173'],\n",
       " [u'1',\n",
       "  u'\"{u\\'type\\': u\\'Polygon\\'',\n",
       "  u\" u'coordinates': [[[-82.87387\",\n",
       "  u' 38.688052]',\n",
       "  u' [-82.87387',\n",
       "  u' 38.76256]',\n",
       "  u' [-82.811927',\n",
       "  u' 38.76256]',\n",
       "  u' [-82.811927',\n",
       "  u' 38.688052]]]}\"',\n",
       "  u'Wheelersburg',\n",
       "  u'United States',\n",
       "  u\"And I'm always tired but never of you\",\n",
       "  u'669375138958307328',\n",
       "  u'1448426444173',\n",
       "  u'3165522051']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltweets_rdd = sc.textFile('./tweets.csv')\n",
    "alltweets_rdd = alltweets_rdd.map(lambda line: line.split(\",\"))\n",
    "print \"Total number of tweets: \", alltweets_rdd.count()\n",
    "alltweets_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bounding_box: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tid: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      "\n",
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "37518\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "alltweets_rdd = sc.textFile('./tweets.csv')\n",
    "alltweets_rdd = alltweets_rdd.map(lambda line: line.split(\",\"))\n",
    "header = alltweets_rdd.first()\n",
    "alltweets_rdd = alltweets_rdd.filter(lambda line:line != header)\n",
    "#alltweets_df = alltweets_rdd.map(lambda line: Row(bounding_box=line[1:10], city=line[10], country=line[11], \n",
    "#                              text=line[12:-3], tid=line[-3], timestamp=line[-2], uid=line[-1])).toDF()\n",
    "alltweets_df0 = alltweets_rdd.map(lambda line: Row(bounding_box=line[1:10], city=line[10], country=line[11], \n",
    "                              text=line[12:-3], tid=line[-3], timestamp=line[-2], uid=line[-1]))\n",
    "alltweets_df = sqlsc.createDataFrame(alltweets_df0)\n",
    "alltweets_df.registerTempTable(\"alltweets_df\")\n",
    "alltweets_df.printSchema()\n",
    "\n",
    "print type(alltweets_rdd)\n",
    "print alltweets_rdd.count()\n",
    "print type(alltweets_df)\n",
    "# note alltweets_df is not and RDD, will not take RDD actions like count() or take()\n",
    "# e.g the following wont work    \n",
    "#print alltweets_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(bounding_box=[u'\"{u\\'type\\': u\\'Polygon\\'', u\" u'coordinates': [[[-82.87387\", u' 38.688052]', u' [-82.87387', u' 38.76256]', u' [-82.811927', u' 38.76256]', u' [-82.811927', u' 38.688052]]]}\"'], city=u'Wheelersburg', country=u'United States', text=[u\"And I'm always tired but never of you\"], tid=u'669375138958307328', timestamp=u'1448426444173', uid=u'3165522051')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ustweets_df = alltweets_df.filter(alltweets_df['country'] == \"United States\")\n",
    "print type(ustweets_df)\n",
    "ustweets_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = sqlsc.sql(\"SELECT * FROM ustweets_df\")\n",
    "#print tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####function to process tweet texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "processed_tweets = ustweets_df.map(lambda r: process_tweets(r.text))\n",
    "print type(processed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results of SQL queries are RDDs and support all the normal RDD operations.\n",
    "#teenNames = teenagers.map(lambda p: \"Name: \" + p.name)\n",
    "#for teenName in teenNames.collect():\n",
    "#  print(teenName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On my Mac\n",
    "#milliontweets = sqlsc.read.json(\"/Users/akinyi/Downloads/omtm.json\")\n",
    "#milliontweets = sqlsc.read.json(\"./omtm.json\")\n",
    "milliontweets = sqlsc.read.json(\"./result.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[coords: string, country: string, lang: string, place: string, timestamp: string, ttext: string, tweetid: string, userid: bigint]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milliontweets.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- coords: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- place: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- ttext: string (nullable = true)\n",
      " |-- tweetid: string (nullable = true)\n",
      " |-- userid: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "milliontweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milliontweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----+-----------------+-------------+--------------------+------------------+----------+\n",
      "|              coords|      country|lang|            place|    timestamp|               ttext|           tweetid|    userid|\n",
      "+--------------------+-------------+----+-----------------+-------------+--------------------+------------------+----------+\n",
      "|47.61493799999999...|United States|  en|      Seattle, WA|1447266708839|After taking publ...|664510856407834624| 537328079|\n",
      "|37.7050435,-122.1...|United States|  en|  San Leandro, CA|1447266710015|Thankful for all ...|664510861340340228|3896359752|\n",
      "|37.7706565,-122.4...|United States|  en|San Francisco, CA|1447266716814|@Priz I've been w...|664510889857433600|  15532647|\n",
      "|26.27026099999999...|United States|  en|Coral Springs, FL|1447266717060|@awolnation it's ...|664510890889342976|1064780006|\n",
      "|39.7795625,-86.14...|United States|  en| Indianapolis, IN|1447266716818|@bobandtom VIP ca...|664510889874186240|  63448519|\n",
      "+--------------------+-------------+----+-----------------+-------------+--------------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "milliontweets.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expecting object: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0278a267f3a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#line_generator = open(\"./small.omtm.json\").read()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mline_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mactor_id_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/akinyi/anaconda/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/akinyi/anaconda/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \"\"\"\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/akinyi/anaconda/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \"\"\"\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No JSON object could be decoded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expecting object: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#line_generator = open(\"/Users/akinyi/Downloads/omtm.json\")\n",
    "#line_generator = open(\"./small.omtm.json\").read()\n",
    "for line in line_generator:\n",
    "    line_object = json.loads(line)\n",
    "\n",
    "    actor_id_string = line_object[\"source\"][\"text\"]\n",
    "    #actor_id = int( actor_id_string.split(\":\")[2] )\n",
    "    #language_code = line_object[\"twitter_lang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./result.json\", \"r\") as fd:\n",
    "    yearinfo = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./omtm.json\", \"r\") as fd:\n",
    "    yearinfo = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsdict={}\n",
    "for y in yearinfo.keys():\n",
    "    yearlist=yearinfo[y]\n",
    "    yearlist2=[]\n",
    "    for idict in yearlist:\n",
    "        singers=idict['band_singer']\n",
    "        for i,s in enumerate(singers):\n",
    "            songs=idict['song']\n",
    "            for j,so in enumerate(songs):#now inside each singer song combination\n",
    "                nd={}\n",
    "                nd['band_singer']=s\n",
    "                nd['url']=idict['url'][i]\n",
    "                nd['song']=so\n",
    "                nd['songurl']=idict['songurl'][j]\n",
    "                nd['ranking']=idict['ranking']\n",
    "                yearlist2.append(nd)\n",
    "    yeardict[y]=pd.DataFrame(yearlist2)#one for each year\n",
    "yearspanel=pd.Panel.from_dict(yeardict, orient=\"minor\")#stack dataframes into a panel\n",
    "hierframe=yearspanel.to_frame() #flattening leads to a hierarchical index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
